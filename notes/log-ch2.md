**Project Log**

# Upstream oil and gas production and ambient air pollution in California

### Meta
- **Authors:**
  - David J.X. Gonzalez, djxgonz@stanford.edu
  - Christina K. Francis, cfranc22@jhu.edu
  - Gary M. Shaw, gmshaw@stanford.edu
  - Mark R. Cullen, markcullen909@gmail.com
  - Mike Baiocchi, baiocchi@stanford.edu
  - Marshall Burke, mburke@stanford.edu
- **Submissions:**s
  - Peer review
    - Science of the Total Environment (STOTEN) [submitted: 4.12.2021; revision 1: 5.20.2021 to 8.16.2021; revision 2: 8.31.2021; accepted: 9.8.2021]
  - Preprint
    - medRxiv [submitted: 4.12.2021; rejected: 4.12.2021 b/c not clinical]
    - EarthArXiv [submitted: 4.13.2021; posted: 4.14.2021]
- **Presentations:**
  - IAPHS 09.2020 - DG
  - AGU 12.2020 - CF

---

### Manuscript Details

- **Highlights**
  -	Oil and gas wells have been linked to adverse health, but mechanisms not well understood
  -	Applied a quasi-experimental design with daily air pollution and oil production data
  -	We leveraged wind direction as source of exogenous variation for exposure to wells
  -	Upstream oil and gas production produced air pollutants at concentrations that may be harmful
  -	Validated that proximity is an appropriate indicator of air pollution exposure from wells
- **CRediT author statement**
  - David J.X. Gonzalez: Conceptualization, Data Curation, Methodology, Formal Analysis, Visualization; Writing - Original Draft, Writing - Review & Editing; Christina Francis: Data Curation, Writing - Original Draft; Gary Shaw: Writing - Reviewing and Editing. Mark Cullen: Methodology, Writing - Reviewing and Editing; Michael Baiocchi: Methodology, Writing - Reviewing and editing; Marshall Burke: Conceptualization, Methodology, Supervision, Writing - Reviewing and editing.

---

### 9.7.2021 W
- The paper was accepted!

### 8.31.2021 Tu
- We got minor revisions back from STOTEN, just a few points from the (thoughtfully thorough) reviewer 1
- I turned the revisions around and re-submitted. I think this is a great sign that this paper will, hopefully, be accepted soon

### 8.16.2021 M
- Today I worked on finalizing the materials for our R&R
- I addressed Gary's suggestions for the reviewer comments, and Marshall's comments in the same as well as the manuscript
- On Marshall's suggestion, I revised the formula for our primary statistical model to omit the monitor FE (since it's included in the monitor-month FE) and add an error term
  - Updated LaTeX script for statistical model:
    - Y_{md} = U_{mda} + D_{mda} + O_{mda} + C_{md} + \gamma_{mn} + \delta_{by} + e_{md}
- Our editor was Lidia Morawska; I selected her as the preferred editor again
- APC for gold open access (required now that I'm at a UC) is $1,890; includes a substantial discount with my UC affiliation
- Comments to publication office:

  Dear Dr. Morawska and Editorial Staff,

  Thank you for the opportunity to revise our manuscript. Thanks also for your patience with us as we have worked on this revision; I have taken both personal and family medical leave since receiving the revision request, which slowed down progress on revising the manuscript. We've addressed each of the reviewers concerns and responded to all comments submitted to us. Based on these comments, we made edits that improved our analysis and in tterpretation of our results. If any questions come up regarding the manuscript, I am available by phone and email. Since submitting this manuscript I completed my doctoral program and started a postdoc at a new institution; these changes are reflected in the title page.

  Sincerely,
  David J.X. Gonzalez, PhD


### 7.26.2021 M
- We got an extension to next Tuesday, 8.3
- I started a new memo to examine missingness in the air quality data

### 7.10.2021 Sa
- I've been working on the revisions for the manuscript based on reviewer comments. I've made good progress, with help from Christina, but there's still a few additional analyses to do
- I requested a second extension to Friday 7.16. I'm confident I can get it done by then, with a big push on Tuesday to get those analyses done

### 7.1.2021 Th
- I'm back to work after my post-dissertation defense vacation
- I got myself organized today and started revisiting the reviewer comments. I'll make this a priority tomorrow

### 6.7.2021 M
- We got a revise and resubmit from STOTEN! We received this on 5.20, but I've been too busy with the dissertation to respond until now

### 4.14.2021 W
- The preprint is now available on EarthArXiv: https://eartharxiv.org/repository/view/2248/

### 4.12.2021 M
- I followed up with Mark C via email to see if he had any more comments -- got the all clear from him!
- I uploaded and submitted the manuscript on medRxiv!
- I didn't realize this, but they'll need to screen the manuscript before posting it. This usually takes 4-5 days. I'll be ready to share and Tweet this out ASAP once it's posted.
- I also finalized the manuscript and prepared it for STOTEN
- Suggested reviewers: Name (first and last) - Institution - Email - Reason
  - Lisa McKenzie - University of Colorado, Denver - lisa.mckenzie@cuanschutz.edu - Has published several papers on exposure to hydraulic fracturing and adverse health outcomes in Colorado
  - Nicole Deziel - Yale University - nicole.deziel@yale.edu - Has published several papers on exposure to hydraulic fracturing and adverse health outcomes in Pennsylvania
  - Longxiang Li - Harvard University - lol087@mail.harvard.edu - Published a recent study on oil/gas exposures and exposure to radioactivity
  - Élyse Caron-Beaudoin - University of Toronto - elyse.caronbeaudoin@utoronto.ca - Published a recent study on oil/gas exposures and adverse birth outcomes in British Columbia, Canada
  - Onome B. Ogheneteg - University of Ibadan - tegabonome@gmail.com - Published a recent study on oil/gas exposures and infant health in Nigeria
- I hit submit!
- Quick update: we got a speedy rejection from medRxiv because the paper doesn't include clinical data. I submitted to EarthArXiv (https://eartharxiv.org/) as a backup option, I think it's a better fit for our scope.

### 4.9.2021 F
- At this point, I'm only waiting on final approval from Mark before we submit. I sent a gentle reminder with a lightly revised manuscript draft yesterday. I think we're there, but of course want to get Mark's input before we put our work out there in the world!
- So, in the meantime, I worked on the submission materials
- I drafted a cover letter and highlights
- I put together the graphical abstract, drawing from figures 2 and 3

### 4.3.2021 Sa
- I reviewed the STOTEN author guidelines and noted the requirements; listed below
- I also looked at medRxiv's formatting requirements, which are pretty straightforward; also below
- medRxiv
  - The simplest way to deposit a manuscript on medRxiv is to upload a single PDF including the text and any figures/tables. All manuscripts should include the title, author names and affiliations, and abstract on the title page. Supplemental data should be created in a separate file or files.
- Science of the Total Environment (STOTEN)
  - provide materials
    - Cover Letter - The corresponding author must state explicitly in a paragraph how the paper fits the Aims and Scope of the journal. Failure to include the paragraph will result in returning the paper to the author.
    - manuscript
    - graphical abstract
    - highlights
      - short collection of bullet points that capture the novel results of your research as well as new methods that were used during the study
      - Highlights should be submitted in a separate editable file in the online submission system. Please use 'Highlights' in the file name and include 3 to 5 bullet points (maximum 85 characters, including spaces, per bullet point)
      - Here is an outline of what the highlights should contain: What is the overall scientific problem and why did you study it? How did you address the problem, and which spheres are included? What was the major method used? Major finding(s) Take home message
    - declaration of competing interests
    - Figures and tables - Please submit Figures and Tables in separate files in an approved format (TIFF or EPS with the correct resolution for figures and MS Office files for tables).
    - CRediT author statement
      - David J.X. Gonzalez: Conceptualization, Data Curation, Methodology, Formal Analysis, Visualization; Writing - Original Draft, Writing - Review & Editing; Christina Francis: Data Curation, Writing - Original Draft; Gary Shaw: Writing - Reviewing and Editing. Mark Cullen: Methodology, Writing - Reviewing and Editing; Michael Baiocchi: Methodology, Writing - Reviewing and editing; Marshall Burke: Conceptualization, Methodology, Supervision, Writing - Reviewing and editing.
    - Data - link to GitHub repository
  - format for STOTEN
    - number the section headings (not the abstract)
    - add continuous line numbers
    - separate the conclusion, can still be part of the discussion
    - references, any style okay
    - add funding
      - This work was supported by the Ford Foundation Predoctoral Fellowship, the Vice Provost for Graduate Education at Stanford University, and the Stanford School of Earth, Energy, and Environmental Sciences.
  - identify editor to request
    - John Gulliver, University of Leicester
    - Phong Thai, University of Queensland
  - suggest 5 potential peer reviewers - The suggested referees should: (i) not be close collaborators of the authors(s)(ii) not be located in the same institution as the author(s) and(iii) not all be from the home country.
    - Lisa McKenzie
    - John Adgate
    - Nicole Deziel
    - Petros Koutrakis, petros@hsph.harvard.edu
    - Longxiang Li (Harvard)
    - [international]
  - draft cover letter, one paragraph on why the article is a good fit
    - First study to validate proximity as an exposure metrics for air pollution in epidemiological studies of exposures to oil and gas wells
    - Relevant to researchers and policymakers
    - Also relevant for other settings around the world where residents are exposed to upstream oil and gas production

### 3.31.2021 W
- I set up an author account for Science of the Total Environment, our first-choice journal for submission
- I finished revising the manuscript (draft 05) based on co-author feedback
- I finished filling in the data for Tables S4 and S5
- I sent the abstract to Mike with a note that at this point the draft incorporates comments from all the other co-authors

### 3.30.2021 Tu
- At this point, I have comments on the manuscript from all co-authors except Mike B. The comments have all been minor, and I think we'll be ready to submit soon!
- I revised the manuscript based on comments from Gary and Marshall
- I filled in the point estimates and SEs for Tables S4 and S5
  - Note to self: for these tables, we converted O3 from ppm to ppb due to small magnitude point estimates (differs from Table 1)

### 3.23.2021 Tu
- Polynomial models, qualitative summary of models
  - Preprod
    - PM2.5 - does not change the results substantially, no indication of nonlinearities
    - CO -
    - NO2 -
    - O3 - No substantial changes, except strange decrease at 3-4 km upwind in the polynomial
    - VOCs - Strange results; substantial decreases within 2 km
  - Prod

### 3.16.2021 Tu
- I fit models for the 60° sensitivity analysis for upwind production volume exposure and exported the point estimates and 95% CIs
- I made the production volume half of Figure S4
- I still need to re-do the analyses for preproduction well count
- I made Table S3, with Pearson's correlation coefficients for preproduction wells and production volume out to 5 km.

### 3.8.2021 M
- After inspection, it looks like the exposure assessment for the 60 degree exposure assessment failed, at least for preproduction count. For at least 3 days, there are more upwind 60° wells than all wells; and for most of the 60° upwind monitor-days, the days with high exposure don't match the 90° days. This could indicate a bigger problem. I'll need to look into it and verify both the 90° and 60° days. I'll also look at the initial prod volume 60° exposure assessments too (2006 and 2007 are done) to look for potential errors. Hopefully this is just an issue with the 60° assessment.
- Some encouraging news -- I don't see this issue when I look at the 60° exposure asssesment for production volume, but rather I see what I'd expected; similar but slightly smaller
- I re-started the preprod count 60° assessment, but using the same wells_interim dataset I used in the 90° primary assessment (I'd recently revised the dataset, but for now I'll replicate the original study)

### 3.7.2021 Su
- I updated the project log and revised the tasks list; we're getting close to the finish line!
- I troubleshooted the Ch. 2 upwind exposure assessment with 60°; I needed to fix the function so it’d work with flexible upwind angle input. It seems to work; I walked through the function line-by-line with a sample dataset and checked it agains the 90° exposure assessment dataset, which checked out.
- For this assessment, we can restrict to assessing exposure only for monitor-days where there was upwind exposure in the 90° upwind assessment, so that’s how I set it up.
- It should be done tonight for preprod, and tomorrow for prod vol. Then I should be able to run the models and make the supplemental figure tomorrow. With that, I’ll call it a day!

### 3.6.2021 Sa
- I made tables S1 and S2, while watching Marvel movies all day. It was slow going but I'm glad this work is done; not many analytic hurdles remain!

### 3.2.2021 Tu
- I added a `month_length_days` variable to the `calgem_production_monthly` and `aqs_daily_annuli_exposure`, then used that to convert the exposure variables for production volume from BOE per month to BOE per day
- With the changes I've made, the units for `aqs_daily_annuli_exposure` for all production volume exposure variables is 100 BOE, to go into all of the models.
- I re-ran all primary analyses for preproduction and production wells, using monitor-month FE (in lieu of basin-month FE); for production volume models, the exposure was in units of 100 BOE total production volume
- I re-made Figures 3, 4, S2, and S3 with the revised results
- Also worked on the manuscript draft. I updated the abstract and results, and expanded the discussion section, particularly some of the nuances.

### 2.25.2021 Th
- I looked into oil/gas production activities in Lost Hills around the time of the SNAPS monitoring campaign. There appears to possibly be an effort by industry to bias the findings. Preproduction activities continued at a similar pace during the monitoring period as before/after the monitoring period. However, all of the n = 55 wells that were in preproduction during the monitoring period were drilled west/southwest of the monitor, during the season when the wind predominantly blows from the northwest. In our study of air pollutant emissions from oil/gas activities, it was important to incorporate wind direction into the analysis. Other wells were drilled to the northwest in 2019, but all of those wells were in preproduction outside the monitoring period. Therefore, the SNAPS monitor is likely to underestimate exposure experienced by the community outside the monitoring period.
- Need to re-run no wind analyses for: production, O3, NO2; preproduction, VOCs

### 2.20.2021 Sa
- I revised Figures 3 and 4 to omit NO; we already have NO2 which I've seen used as a general indicator of NOx in the past; I don't think it adds to much to have both. Also, Casey M suggested simplifying the results figures and I think this is a reasonable way to do that
- Christina F shared a note summarizing a 2007 paper that investigated pollutant composition of smoke plumes; one of the takeaways is that smoke plumes can affect concentrations of CO, NOx, and VOCs.
- This makes me think that we should adjust for smoke in all the models. That would restrict our analyses to 2006-2019, but we still have plenty of data with that criteria (> 1 million monitor-days).
- I sent a Slack message to Christina to see if she thinks that's a good idea
-

### 2.18.2021 Th
- I revised the `aqs_annuli_daily_exposure.rds` dataset to omit monitor-days only with data for PM10; that turned out to be nearly half the dataset! Again, this would've been great to figure out earlier to speed up the exposure assessment; that said, having done the exposure assessment, I have found a robust null effect of exposure to preproduction and production wells on PM10 concentrations. That may or may not be worth including in the analysisI put the old dataset in the
- I think I should omit the results for NO and include NO2; I've seen NO2 used as an indicator of NOx concentrations, so I think it would make sense to

### 2.15.2021 M
- I fit the primary models for production volume and generated Figure 4 and added bar plots for monitor-days with exposure.
- I also revised Figure S3 to add the point estimates for production volume without wind direction.

### 2.13.2021 Sa
- Look into correlation:
  - Annulus to annulus *within* monitors by production stage, i.e.,

### 2.11.2021 Th
- I finished revising the `wells_interim` analytic dataset.
- Revised LaTeX script for statistical model:
  - Y_{md} = U_{mda} + D_{mda} + O_{mda} + C_{md} + \gamma_{mn} + \delta_{by} + \lambda_{m}
- Max monitor-day count
  - PM2.5
    - upwind max = 2877
    - downwind max = 3011
  O3
    - upwind max = 8980
    - downwind max = 11337


### 2.10.2021 W
- I worked on revising the `wells_interim` analytic dataset
- I downloaded the all wells dataset (in csv format) from the CalGEM website
- I also downloaded the full dataset of California wells from Enverus DrillingInfo

### 2.9.2021 Tu
- An issue I've been aware of for a while is the apparent lack of well preproduction dates (spudding, completion) for the most recent years. Last month I downloaded the revised all wells dataset from the CalGEM site and I finally got around to comparing current analytic dataset side-by-side with the revised dataset. As I'd suspected, in the revised dataset there are many hundreds of wells with preproduction dates that weren't included in the current dataset I'm using.
- Current analytic dataset derived from CalGEM all wells dataset, `interim_wells` (year, n completed wells)
  2018	11
  2017	621
  2016	840
  2015	2221
  2014	3618
  2013	3626
  2012	3497
  2011	3069
  2010	2356
  2009	1904
  2008	1217
  2007	777
  2006	577
  2005	482
  2004	384
  2003	299
  2002	326
  2001	359
  2000	327
  1999	195
- Updated raw CalGEM all wells dataset for 2021 (year, n completed wells)
  2016	914
  2017	948
  2018	898
  2019	1276
- I'll re-make the `wells_interim` dataset to incorporate these new data. I'll also check to see if the counts are accurate for pre-2016 wells, too


### 2.8.2021 M
- Today my first goal is to incorporate the 2018-19 monthly production volume data so that we can assess exposure to those wells
- I revised the tidyProductionData1819() function to remove the extraneous first 2 and last 2 digits from api_number (the dataset that includes lat/long doesn't have these digits)
- Most of these have lat/longs available
  - of the 88,867 wells with 2018/19 production data, I was able to match 88,507 of them to lat/long (96%)
  - of the 2,057,806 well-months in the 2018/19 dataset, I was able to successfully match 2,003,914 (97.3%) to lat/long
  - of the 451,541,321 BOE of total oil and gas produced by these wells, we had lat/long associated with 436,570,743 (96.7%) of the production volume
- I was able to successfully create an analytic dataset for prod volume 2018-19, with some missingness
- I ran the tidying function on the 2018-2019 CalGEM monthly production data, imported the existing analytic dataset with the 1999-2017 data, bound the rows, and saved the resulting final analytic dataset as `data/interim/calgem_production_monthly.rds`
- I walked through the prod volume daily no wind exposure assessment function line-by-line. It works. It would likely be more efficient to do the exposure assessment once for each monitor-month, since the exposure data are duplicated; however, I don't think it'll take too long to do the full exposure assessment
- I revised the wind exposure assessment fxns to flexibly take in different angles (i.e., so we can use 60 degrees instead of 90), basically re-making the script that Christina F had pushed to GitHub last week (I'm having trouble syncing to GitHub on my new machine)
- At this point, we should be all set to run our final exposure assessments:
  - preproduction
    - daily annuli upwind sum, 60°
  - production
    - daily annuli upwind sum, 90° (1999-00, 2017-19)
    - daily annuli upwind sum, 60°
    - daily annuli windless sum
- Running on both of my personal machines, I think I can get these done by the end of this week, maybe into next week. Once I have this, I can sort through the results and bring this project to the finish line!
- I'll prioritize the remaining years of the production volume 90°, followed by the windless, followed by the 60°. Let's do this!

### 2.6.2021 Sa
- Today I focused on figures and tables
- I revised the script to make Figure 2, changed to the new color scheme and added code at the end to generate presentation figures (with black background)
- I outlined a Table S1, with descriptive statistics for monitor exposure, and S2, with descriptive statistics for the wells themselves. I still need to fill them in
- I also reviewed the 2018-2019 production volume data; these have API numbers but we need to clip off the first and last two digits to match our wells_interim dataset (to get the lat/long)

### 2.5.2021 F
- I revised the code Figure 4 and re-made the figure. I still need to finish the prod vol exposure assessments (for 2018-19) and generate final point estimates; I also need to try some alternative methods, e.g., top-coding months with high production

### 2.4.2021 Th
- I finished the sensitivity analysis for PM2.5, where I excluded the 35,422 monitor-days with PM2.5 observations with smoke plumes overhead
  - That's 7.8% of the analytic dataset for PM2.5 (note that it's 2006-2019, because that's when the smoke data are available)

### 2.3.2021 W
- For the confusing CO result, where we found a decrease in [CO] for both upwind and downwind wells at 1-2 km, most of the estimates are coming from two monitors (060370031 in Los Angeles County and 060131002 in Contra Costa). For both of these monitors, the periods with exposure happens to coincide with times when the residuals (from the adjusted FELM) are mechanically lower. There seems to be seasonal and secular trends that aren't well controlled for in the current model. I'm not 100% sure what to do next, but my overall impression is that the association we observed is spurious.
  - See the 2021.02-carbon_monoxide_result.Rmd memo for figures and details
  - I sent a message to Marshall with this summary
  so the other thing to try is a monitor x month FE - basically taking out the seasonality at a monitor level.  since you have a long time series at most stations this should be fine in terms of not killing all your variation. so instead of monitor Fe you have monitor-month FE (i.e. 12 dummies per monitor) and then air basin x year

### 2.2.2021 Tu
- Sensitivity analysis of PM2.5 result (for preprod) with smoke days excluded: similar result to adjusting for smoke days, similar coefficients for upwind exposure and statistically significant; no association with downwind wells
  - To do: add this to the manuscript, generate a supplemental figure (in the Rmd script is fine)
- I revised Figure 3 to restrict it to wells within 5 km (which is a better fit with our findings) and to make it more Tufte-friendly for publication

### 1.27.2021 W
- I'm planning to edit the annuli exposure assessmnet script to incorporate flexible angle.
- Also added a script for converting exposure measurements to quantiles;I don't think quantiles makes sense, however, so I'll remove that script in a later iteration.
- Made

### 01.20.2021 W
- I checked the CalGEM website to see
- I downloaded a .csv from Enverus DrillingInfo of wells completed between 01.01.2016 and 12.31.2019
  - There may be additional wells spudded in that range that don't have a completion date and should be included in the analytic dataset

### 01.19.2021 Tu
- I conducted initial analyses using the daily production volume exposure data
- I ran into an issue while fitting the models; I got error terms for some of the models that resolved when I restricted the analysis to production within 5 km; I didn't need to do this for all pollutants
- Consider restricting Figure 4 (and 3?) to exposure within 5 km instead of 10 km
  - I'll wait until I have the exposure assessment for 2001 and 2016 to make this decision
- I encountered an issue with the exposure assessment that, apparently, means I've spent a lot of time doing redundant computing. For the data going into the exposure assessment, I haven't restricted to the monitor-day; rather, I assessed exposure for all rows in the AQS dataset. Unfortunately, this dataset includes redundant rows in, e.g., cases where we observe multiple pollutants for the same monitor-day. This is very frustrating, as this analysis has slowed us down quite ab it. However, the good news is that we can make the remaining robustness checks faster!
- For the remaining exposure assessments (random wind direction, 60° wind data) I need to verify that aqs_data_in has only one row for each monitor-day
- Initial results for daily annuli production volume, marginal increase of 1,000 BOE:
  - PM2.5 - increased at 0-2 km (only statistically significant for 1-2 km)
  - CO - decreased at 0-2 km
  - NO - decreased at 0-2 km
  - NO2 - no change
  - O3 - decreased at 0-1 km, slightly increased at 1-2 km
  - SO2 - increased at 0-1 km (for both upwind and downwind)
    - This time with data from 5 monitors, 3 from LA County, 1 from Contra Costa, 1 from Santa Barbara (likely the same one by Vandenberg from the preprod analysis)
  - VOCs - no significant effect within 2 km, slight increase at 2-3 (doesn't make sense physically, though)
- An increase in 1,000 BOE is comparable to the sum of total production volume from 22.2 producing wells (median production for all well-months is 45 BOE)
- I made a revised draft of Figure 3 and an initial draft of Figure 4

### 01.18.2021 M
- Still need to do exposure assessment for downwind production volume using primary parameters for 2001 and 2016
- In the meantime I conducted the exposure assessment for

### 01.11.2021 M
- I verified the units for Tables 1 and 2
- Note that in Table 1, the O3 unites are ppm, but in Table 2 I used ppb; that's because point estimates for O3 were very small so I converted to ppb
  - Make sure to note this in the paper
- I added day-of-week to all the regression models and revised Table 2 to reflect the changes
- Day-of-week didn't substantially change any of the results, but I think it's something we should control for anyway, particularly for PM2.5
- Table 1 had erroneous data for O3; I fixed it. Note that the NAAQS 8-hour standard is 0.07 ppm
- The VOC data (nmoc_total) are messed up, we only have ~50 observations total. This likely happened when I re-made the analytic dataset, which I did while I was incorporating the daily smoke plume data. I'll revisit the steps I took and see how to fix it. In the meantime, we don't have results for VOCs
- CalGEM production, summary statistics for total oil/gas produced per month (in BOE)
  - median: 45.8
  - mean: 304.0
  - sd: 1,539.8
  - range: 0, 1500772

### 01.06.2021 W
- Daily annuli preproduction upwind
  - PM2.5
    - Polynomial - No evidence of non-linearities
  - CO
    - Polynomial - *Evidence* of non-linear/squared response
  - NO
    - Polynomial - *Evidence* of non-linear/squared response
  - NO2
    - Polynomial - No evidence of non-linearities
  - O3
    - Polynomial - *Evidence* of non-linear/squared response
  - SO2
    - Polynomial - No evidence of non-linearities
  - VOCs

### 01.04.2021 M
- For my writing task today, I reviewed and edited the current draft of the manuscript, to get my head back into this project
- I kept the exposure assessment running over winter vacation. We now have all the exposure data to do the primary analyses, including getting final-ish results for exposure to production volume
- I still need to conduct exposure assessments for most of our robustness checks, including: downwind exposure (for production volume), random wind direction (for preproduction count and production volume), and the more narrow caliper of 60° (for preprod and prod)
- To make the analysis more efficient, I'll learn how to submit jobs to Sherlock. I'll also be able to do more analyses simultaneously once my new MacBook Pro arrives, possibly by the end of the week!

### 12.23.2020 W
- I revised the `aqs_sites` dataset to add new monitors with CO and NO data, now that I'm including that in the analysis
- Finalized the analytic dataset with preproduction exposure data, with only one row for each monitor-day; there's a script to re-do this if needed, but it's a bit of a mess (but it works!)
- We're all set for analysis, the dataset should include anything
- I revised Table 1

### 12.20.2020 Su
- I manually assigned zip codes for 23 of the monitors, which don't intersect with zip codes from the 2010/2019 U.S. census zip code because they're in natural areas, e.g., national parks.
  - Monitors with these IDs: 60295001, 60834003, 60430003, 60832012, 60893003, 61030004, 60650008, 60431003, 60651004, 60711001, 60431005, 60650010, 60930005, 60519000, 60270022, 60270024, 60270025, 60270026, 60270028, 60270029, 60270030, 60450002, 60530007

### 12.17.2020 Th
- From Sam H-N graciously following up on my request for zip code-day level smoke plume data:
  "I didn’t have a perfect zip by day data set ready to go but I had something that gets you close and then you can fix the one remaining issue if you feel the need (explained below).
  I had a plume by zip by day data set ready to go that covers all those years (ie zip-days have multiple rows when more than 1 plume is overlapping). I grouped by zip-day and counted the number of plumes (variable “n_plumes”) and created an indicator for whether any plume overlapped the zip-day (“smoke_day”).
  This is what is in the attached “zip_by_day_smoke” file for 2006 to 2019. It has 1 row for every zip-day where the number of overlapping plumes > 0. Therefore the smoke_days indicator is currently all 1s. Once you merge this with your data on zip and date then you can replace missing values from non-match with 0 because if a zip-day was not in the attached data it almost always means there was no smoke. This is not quite a perfect system though because it doesn’t distinguish days where there was no smoke from days where there is no plume data because of some issue with the satellite images. In most years there are only a few days with missing plume data but here they are being assigned no smoke. So if you want to ignore the issue you can use the attached data as is.
  I also attached a list of the all the dates we do have plume data for (“days_with_smoke_data”). The date format is YYYYMMDD. If you want to make sure you’re not attributing a missing data day to 0 smoke you can use this list of dates to figure out which days plume data are missing for and then set all smoke_day values to NA for those days.
  All of this makes sense in my head but feels confusing when I write it out so definitely let me know if you have clarification questions."


### 12.09.2020 W
- I kept running the downwind prod volume exposure assessment for 2002
- I worked on the methods section for the manuscript and outlined supplemental figures and tables I need to make
- I also outlined the robustness checks I'd like to do, building on a talk by Tatyana Deryugina I saw earlier this week
  - For one of the robustness checks, I'll randomize the wind direction (instead of randomly permuting the locations of wells)

### 12.08.2020 Tu
- I made some additions to the manuscript draft
- I started the downwind production volume exposure assessment, starting with the data for 2002

### 12.07.2020 M
- I'm still running the upwind annuli prod volume exposure assessments. We're past the halfway point. I'll spend some time this afternoon doing preliminary analyses to get a sense of the data.
- I conducted the preliminary analyses for the production volume exposure assessment data we have so far. There seems to be an increase in SO2 within 2 km and inconsistent results for the other pollutants, including PM2.5.
- I made a draft Figure 4 with the preliminary results
- I also revised Figure 2, to show how we assess exposure to wells in both preproduction and production stages

### 12.01.2020 Tu
- Over Thanksgiving break I finished the production volume annuli exposure assessment with ~90° (that still needs to be fixed) for all the even years from 2008-2016 (though I expect missingness in the prod volume to be an issue after 2013)
- There was an error in the earlier exposure assessment code that resulted in the upwind/downwind vector not actually making the triangle point upwind/downwind (oops!). I fixed this error in the revised code, and compared output from the revised exposure assessment function with output from the older code. There was a difference. I'll need to discard exposure assessments done before 11/24 (when I started with 2010 data using the revised function) and re-do them. I re-did 2008 already for comparison (that's where I found the error). I'll need to re-do some of the odd-numbered years that Christina already did before I found the error (sorry, Christina!).
- I did a preliminary analysis using the data for 2008, 2010, and 2012; we're still finding a clear signal for increased PM2.5 out to 2 km in this preliminary analysis. I'll need to do more, of course, but this fits our hypothesis that increased production results in higher air pollution concentrations. I'd also like to do some sort of discontinuity analysis comparing months where production ramped up quickly.

### 11.26.2020 Th
- 2012b and d ran lastnight (for annuli upwind prod volume), but not c; I'm not sure why. It looks like I may have skipped it by accident. Confirm that the monitor_dates for 2012b and 2012d are what they should be!

### 11.23.2020 M
- Today I worked on setting up a workflow that uses parallel processing to handle calling the exposure assessment with the wind data `mclapply`
- Started at 2:57pm with 1,000 rows of data for 2010. It finished and exported at 3:30pm, for 33 minutes total. This is slower than the code I ran on Friday.
- There's a major issue though—-it didn't work. It didn't assess exposure to any production volume. I'll need to go through the code line-by-line to see what went wrong.
- I found the error; I mixed up the monitor lat/long in the exposure assessment function. I fixed this in the function and tested it line-by-line on one of the data points. It works. I'll re-run the `mclapply` call.
- I started the exposure assessment for the first 1,000 rows of data for 2010 at 3:46pm. It finished and exported at 4:19pm, again for 33 minutes total. This is still substantially faster than the for loop method, though not as fast as I'd hoped. There may be more improvement when I run the script on a longer list object (i.e., scaling up the data may bring more gains).
- I called the function for rows 1001-10000 of the 2010 dataset at **4:32pm**. It finished at **8:06pm**, for 186 minutes total. That means I've sped up the process slightly more than 2x from the older code! I estimate it takes ~3.6 hours per 10000 rows of data.
- Major problem, however--it's still not taking the sum of exposure. Idk what's going on here, I thought I'd solved the problem earlier!
- Okay actually no problem at all, I just forgot to update the function after I fixed it earlier. It works when I test it on sample data. I'll re-do the first 10,000 rows of data for 2010!
- I think there may have been an error in the prod volume exposure assessment for the years we've already done, given that there seemed to be some mixing up of lat/long. So far, we've assessed prod volume exposure for: 2001-2004, 2006, and part of 2008 (up to row 50,000). To verify this, I can re-do a subset of the analysis and see if it matches; if not, I'll need to re-do it, but it should be faster now. It may make sense to ignore those years in preliminary analyses, then re-do those analyses once I've resolved the angle issue (described below).
- Also, the angle for the upwind/downwind wedges is clearly not 90°, but a bit smaller. I'm not sure why, but I'll need to go back into the exposure assessment function and fix this issue. That means I'll likely need to re-do *all* the analyses we've done so far. However, I think it makes sense to continue doing the analyses while I sort this issue out.
- I called the `mclapply` for the first 10,000 rows of 2010 data for the exposure assessment at **8:30pm**. Since this will be running overnight, I also called the next 10,000 rows of data.
  - It finished at **11:44pm**, a bit earlier than I'd expected!

### 11.20.2020 F
- I finished revising the script to call the `assessExposureAnnuliVolumeWind` function using `lapply` instead of a for loop.
- To do this, I had to convert the `aqs_data_in` object to a list. The list appears to take up a lot of memory and handling it seems slow, though it's much faster when I feed it into the `lapply` call!
- When I was revising the function, I encountered a potential issue that could be a problem for earlier data.
- I called the function on 1,000 rows of data at 3:46pm (without multicore), done at 4:09pm. 23 minutes total. **This is about twice as fast as the earlier code with the for() loop, and I haven't implemented parallel processing yet!**

### 11.17.2020 Tu
- I'm making Table 1 today, to summarize the descriptive statistics for the monitors, air pollutants, and meteorological factors
- When I filter only to monitor-days where we observe pollutants of interest, we retain 360 of the monitors in the overall dataset. That means some o monitors represented in the current Figure 1a draft don't contribute data to the study. I'll need to revise Figure 1a.
- I finished the draft of Table 1.
- I converted the Ch. 2 outline in Atom to a Word document, to incorporate the Tables and start writing in earnest.
- The units for NARR APCP (accumulated precipitation) are kg/m^2/day
  - To convert kg/m^2/day to mm/day, multiply by 1.44

### 11.16.2020 M
- I presented our preliminary findings to date to Wade Crowfoot, Secretary of the California Natural Resources Agency (CNRA), and Matt Baker, deputy secretary of energy. I think it went pretty well; Sec. Crowfoot is pretty high up the food chain so I think the details were less relevant than the fact that there’s new research that should be considered. He said he'll passing me along to the scientific panel they’re convening, chaired by Seth Shonkoff and Rachel Morello-Frosch. That said, I think it’s good that I was able to share our preliminary evidence  finding evidence of pollution out to 2 km away from wells
- Kept the exposure assessment running; nearly done with 2006
- I figured out to copy data from my machine to the Sherlock HPC. It was much more straightforward than I thought! Remember: I need to call the `scp` function from terminal without logging into the remote server! Tomorrow I’ll see if I can schedule a job to run the exposure assessment code; maybe the 60° sensitivity analysis?

### 11.13.2020 F
- I finished the 2004 daily annuli upwind production volume exposure assessment:
  - 2004a - rows 1-10,000
  - 2004b - 10-20k
  - 2004c - 20-30k
  - 2004d - 30-40k
  - 2004e - 40-50k
  - 2004f - 50-60k
  - 2004g - 60k-end
- I started the 2006 daily annuli upwind production volume exposure assessment

### 11.13.2020 F
- I revised Figure 2, with a step-by-step visualization of the upwind and downwind exposure assessment, now with colors that match Figure 3

### 11.12.2020 Th
- Outlined presentation I'm giving to CA Secretary of Natural Resources Wade Crowfoot on Monday
- Christina F uploaded 2001 daily upwind production exposure data to Box; I downloaded it to my machine and wrote a script to bind the rows for all the exposure assessment data we have so far
- I revised Figure 2

### 11.11.2020 W
- I did an analysis stratified on air basin using the shapefile from CARB
- Results from urban/rural stratification:
  - PM2.5 - San Joaquin Valley, higher concentrations of PM2.5 at 2-5 km, with 1.8-2.6 µg/m^3 increase in PM2.5 per additional well (no upwind wells exposure at 0-2 km, but likely similar). South Coast, 1.7 µg/m^3 higher concentration of PM2.5 at 1-2 km
  - NO2 - San Joaquin Valley, elevated NO2 at 2-4 km, no exposure 0-1 km; South Coast, elevated NO2 1-3 km, larger effect size (4.8 at 1-2 km!)
  - O3 -
  - SO2 -
  - NMOC - Insufficient data
- I ran the daily annuli upwind production volume exposure assessment for 2004:
  - 2004a - rows 1-10,000
  - 2004b - 10-20k
  - 2004c - 20-30k

### 11.10.2020 Tu
- The daily annuli upwind production volume exposure assessment continues to run smoothly; I finished the assessment for 2002 and started 2004 (I'm doing even years)
  - 2002a - rows 1-25,000
  - 2002b - 25-30k
  - 2002c - 30-40k
  - 2002d - 40-50k
  - 2002e - 50-55k
  - 2002f - 55-60k
  - 2002g - 60-70k
- For the manuscript, I worked on the abstract and discussion and started outlining the results section
- I did an analysis stratified on urban/rural, using US Census Bureau urban shapefile to classify monitors
- Results from urban/rural stratification:
  - PM2.5 - Similar results for urban and rural settings; observed elevated PM2.5 in urban settings out to 2 km, 3/4 km in rural settings [revisit after adjusting for wildfire smoke exposure]
  - NO2 - [to do]
  - O3 - Urban stratum is similar to full pooled analysis; decreased concentration for nearby wells, elevated at 3-5 km. In rural settings, significantly higher O3 concentrations with a monitor within 1 km (upwind or downwind), but no effects beyond 1 km.
  - SO2: Insufficient data for rural stratum; no monitor-days with exposure to wells in most of the annuli bins
  - NMOC - [to do]
- We need to adjust for wildfire smoke exposures! In the rural stratum, there was a large increase in PM2.5 concentrations with exposure to both upwind and downwind wells at 4-5 km. I looked into this and found that this result seems to be coming from a small cluster of consecutive days at a monitor in Tulare in January (as well as some other monitors). I couldn't find any records of coinciding wildfires, but I know from other work that there is agricultural field burning in January in the San Joaquin Valley. So these observations and the seemingly spurious association between the exposure and elevated PM2.5 levels may be attributable to wildfire smoke.
- I sent a message to Anne D on the Burke Lab Slack to ask about getting zip code-level daily indicators of whether or not there was a plume overhead, which I'd like to add to the PM2.5 models.

### 11.09.2020 M
- I continued the exposure assessment daily annuli upwind production volume for 2002 last night. The code ran successfully and I'll plan to keep the code running whenever I'm not trying to analyze the data
- I plan to back up the exposure assessments files on Box, since it takes a long time to process the data
- For the manuscript, I started drafting the abstract and expanded the methods

### 11.05.2020 Th
- The upwind production volume exposure assessment code is slow. Approximately 12 hours since I started the script on the 2002 data, only ~15,000 monitor-days have been assessed.

### 11.04.2020 W
- I changed the primary model to include well counts for both upwind and downwind wells in the same model; this did not substantially change my earlier impression of the results
- I downloaded the urban areas shapefile for the 2010 US census and clipped it to California; this is the same dataset Tran et al. used in their study
- I started a new results Rmd file to look at the results stratified on urban/rural
- There appear to be differences stratifying on urban/rural; for example, we observe an increase in NO2 concentrations in urban and not rural areas
- I finished the script to assess exposure to upwind production volume and tested it on sample data; it works
- I started assessing upwind exposure to production volume for 2002; I'll check the status in the morning. I think this should take a similar amount of time as the drilling sites assessment, but I'll need to confirm that once the code has run

### 11.03.2020 Tu
- I revised the script for assessing exposure to production volume

### 10.29.2020 Th
- Meeting w/ Christina F
  - Agenda:
    - Let's go over authorship expectations so we're all on the same page! There are lots of guides out there, but here's one I think captures the responsibilities of co-authors well.
    - Okay, my goal by this afternoon is to have the scripts set up to do the rest of the exposure assessments. Let's briefly review those and divide the computing work between us (again, prioritizing your computer use for Hopkins-related schoolwork!)
    - Finally, a couple relevant papers have come out in the past couple weeks (Banan and Gernanda, which used a plume modeling approach, and Li et al., which used a similar approach to us but looks at radon) — you don't need to read them, but I'd just like to take a quick look at them together!
- The first order of business today is to identify the monitor-days we still need to do the new wells upwind/downwind exposure assessments for
  -
- Finalize and test the production volume exposure assessment, with and without wind accounted for
  -

### 10.28.2020 W
- I set up a working example to assess daily exposure to oil/gas production volume using annuli.
  - As with the (current) Figure 2, I used data for monitor 060290232 (located in Bakersfield, CA)
- In their exposure assessment, Tran et al. (2020) used total production volume, taking te sum of monthly barrels of oil and barrels of oil equivalent (BOE) of natural gas. I'll use this approach, too.
  - I need to review the raw data/documentation to verify that the oil and gas production volume data are in BOE
  -  I also need to add a variable to the tided calgem_production_monthly dataset that includes total production_volume_boe
- Note on scoping monthly volume we should expect from each well: "Most U.S. oil and natural gas production comes from wells that produce between 100 barrels of oil equivalent per day (BOE/d) and 3,200 BOE/d" ((EIA 2019)[https://www.eia.gov/petroleum/wells/], accessed October 28, 2020)
- 1 barrel of oil equivalent (BOE) = 6 mcf (thousand cubic feet) of natural gas
- I wrote a Rmd notebook to explore the method
-
- I updated the

### 10.27.2020 Tu
- I re-constructed the aqs_monitor_day dataset from scratch. I imported all the raw AQS pollution data, tidied the data, bound the data together into one dataset, and exported it as a .rds file. The dataset now has 2,416,010 rows, about half of what it was before. This is because I omitted the AQS meteorological data, since we now have the NARR data (and since we've already verified that the AQS observed and NARR predicted temperature data are strongly correlated).
- I changed the 'site_id' variable to 'monitor_id' for consistency; I'll need to make this edit in all scripts and Rmd files
- We now have data from 444 AQS monitors throughout California
- I revised Figure 1 to include all the monitors, since this is a large increase in the number of monitors than we had before. I also added outlines for each of the CARB air basins, since this is included as a geospatial FE in the models
- We need to re-construct the NARR temperature, precipitation, and wind datasets to incorporate the new AQS monitoring sites. I asked Christina F to do this data tidying step, since her computer is better set up to work with the large NARR data files (my MacBook Pro automatically deletes the files from my hard disk to conserve space--another reason to upgrade my machine to one with more storage!).
  - Christina confirmed she can do the work!
- I developed a protocol to account for duplicate observations for the same pollutant on the same monitor-day. There are many examples of this, and it seems due to duplicate observations using different parameters. For example, for PM2.5 data, some monitor-days have two observations for daily mean PM2.5 but with different parameter codes; either 88101, the FRM/FEM (the gold standard) or 88502, which is isn't FRM/FEM but is highly correlated with it.
  - Reference: [AQS Memos - Technical Note on Reporting PM2.5 Continuous Monitoring and Speciation Data to the Air Quality System (AQS)](https://www.epa.gov/aqs/aqs-memos-technical-note-reporting-pm25-continuous-monitoring-and-speciation-data-air-quality)
- To add the parameter code to the analytic dataset, I had to revise the data tidying functions to retain and rename that value. I re-tidied all the air quality data and exported it.
- Ideally, I would use the most reliable observation for each monitor-day (FRM/FEM if possible). However, that was logistically difficult to do using dplyr (though I think it is doable). Instead, since the values should be highly correlated, I decided to take the mean of duplicate values for each monitor-day. I don't expect this to bias the results.
- I did this procedure for the PM2.5 and SO2 data with exposure to upwind wells and re-fit the fully adjusted fixed effects regression models. As expected, the confidence intervals were wider but the point estimates were similar to before.
- For each of these analyses, and as others have suggested, I visualized the count of monitor-days with wells within each of the distance bins (0-1, 1-2, 2-3 km, etc.). As expected, there were few monitor-days with wells nearby and more monitor-days with wells further out. I visualized the count using log10 transformation since it was so heavily skewed. I hope this won't be perceived as misleading. I'll make sure to note this as a limitation in the manuscript.
- For PM2.5 and SO2 (and likely the rest of the pollutants), I noticed there are few monitor-days with wells within 2 km. We'll be aiming to make claims based on these data and I want to feel confident with it. The data for wells within 2 km for both pollutants comes from multiple years and multiple seasons, which is helpful.
- Next:
  - finish adding code to results Rmds to remove duplicate rows, then re-fit the models, add bar plots for monitor-days with wells nearby, and re-make Figure 3

### 10.26.2020 M
- I decided on the list of pollutants to include in the final analysis:
  - Gases
    - NO
    - NO2
    - O3
    - SO2
  - Particulate matter  
    - PM2.5
      - Arsenic
      - Chromium
      - Lead
      - Manganese
      - Nickel
  - VOCs
    - All non-methane VOCs
    - Acetaldehyde
    - Acetone
    - Benzene
    - Chloroform
    - Dichloromethane
    - Formaldehyde
    - Tetrachloroethylene
- I tidied the NO, HAPs, lead, and VOCs data and combined it with the aqs_monitor_day interim dataset
  - There appears to be some

### 10.23.2020 F
- Meeting with Joan Casey
  - PM2.5 result is nontrivial, worth writing up
  - NO2 result doesn't quite make sense
  - Stratify on urban/rural
  - Fixed effects may be sufficient to account for other pollution sources; wait for a reviewer to see if we should control for other sources
  - Prediction/cross-validation doesn't make sense unless we want to do a rigorous air quality study bringing in someone who specializes in that; that's not our goal, so I'll leave it as-is

### 10.22.2020 Th
- I finished cross-checking the HAPs data with the Elliott et al. 2017 for the HAPs data;
- Worked on the intro for the chapter, added lit; Allshouse et al.
- I explored the AQS VOCs and NO/NOx/NOy data
  - We should have sufficient observations to include NO, benzene, all non-methane hydrocarbons, and certain PM2.5 species (e.g., arsenic, lead)
  - I still need to look into the lead data!
- I explored the CalGEM production data, which comprises tidied monthly well-level production data from the CalGEM website linked to lat/long via the PWT ID key provided by Kathy Tran
- There is quite a bit of missing lat/long observations for the CalGEM production data (i.e., PWT IDs for which there weren't any lat/long in the key Kathy T shared), but most of the missingness is among well-months without production
- Of the 10,674,563 well-months with oil/gas production, only 326,029 (3.1%) are missing lat/long data. Of that, most missingness for producing well-months is before 2001 and after 2013
  - **We should include a sensitivity analysis restricted to 2001-2013 where missingness is less of an issue**

### 10.21.2020 W
- I downloaded all the prepared daily datasets for HAPs, VOCs, NONOxNOy, and Lead from the EPA Air Quality System web interface
- I wrote a Rmd file to explore the HAPs data. Generally, it appears that we should have sufficient sample size and spatiotemporal variation to make inferences about pollutants of concern, including:
  - acetaldehyde, arsenic (PM2.5), benzene, formaldehyde, lead (PM2.5)
- I made a plot to visualize the location of AQS criteria air pollutants monitors (i.e., the ones we already have analyzed) *and* HAPS monitors (the new sets)
- Of the 66 HAPS monitoring sites in California, 21 are within 10 km (and 0 within 1 km) of at least one drilling site and 24 are within 10 km (and 4 within 1 km) of at least one active well during the study period (1999-2019)
- In addition to HAPS, there is data available on VOCs, NONOxNOy (precursors), lead, speciated PM2.5/PM10 (which I think may be included in the HAPs dataset)
- I started going through the classes of chemicals we have data for from HAPS and verifying whether there is evidence from the literature of an association with oil and gas production, drawing on Elliott et al. (2017) and Stringfellow et al. (2017)
- HAPS pollutant names (specifically, those with sufficient observations for inference) - evidence of association with oil/gas:
  - Evidence of association with oil and gas
    - Acetaldehyde - yes (Elliot et al. 2017)  
    - Acrolein - Unverified[?] - yes (Elliot et al. 2017)
    - Arsenic PM2.5 LC - yes (Elliot et al. 2017)  
    - Arsenic (TSP) STP - yes (Elliot et al. 2017)  
    - Benzene - yes (Elliot et al. 2017, Stringfellow et al. 2017, the Ventura/Lost Hills study found this)
    - Beryllium PM2.5 LC - no
    - Cadmium PM2.5 LC - yes (Elliot et al. 2017)  
    - Chloroform - yes (Elliot et al. 2017)  
    - Chromium PM2.5 LC - yes (Elliot et al. 2017)  
    - Chromium (TSP) STP - yes (Elliot et al. 2017)
    - Dichloromethane  - yes (Elliot et al. 2017)  
    - Formaldehyde - yes (Elliot et al. 2017, Stringfellow et al. 2017)
    - Lead PM2.5 LC - yes (Elliot et al. 2017)    
    - Manganese PM2.5 LC - yes (Elliot et al. 2017)  
    - Nickel PM2.5 LC - yes (Elliot et al. 2017)  
    - Manganese (TSP) STP - yes (Elliot et al. 2017)  
    - Nickel (TSP) STP - yes (Elliot et al. 2017)  
    - Tetrachloroethylene - yes (Elliot et al. 2017)  
  - No evidence of association with oil and gas
    - 1,3-Butadiene - no
    - Carbon tetrachloride - no
    - Ethylene dichloride - no
    - Trichloroethylene - no
    - 1,2-Dichloropropane - no
    - trans-1,3-Dichloropropene - no
    - cis-1,3-Dichloropropene - no
    - Ethylene dibromide - no
    - Vinyl chloride - no
  - Note: It's not clear from EPA documentation I've been able to track down, but I think STP = standard temperature and pressure and LC = local conditions (though I'm not sure what that means)

### 10.20.2020 Tu
- To do a proper comparison between exposure assessment methods, we should consistently use monitor–day as the unit of observation. That means I'll need to set up the analysis with daily IDW and annuli exposure assessments without wind
- Meeting with Mike B:
  - Help us believe that wind direction changes at a particular site from day-to-day; what is the variation in wind direction at each site? We could do a sensitivity analysis restricted at areas where wind is highly variable.
  - Additional pollutants we can test for as a null test? (CO and PM10?)? Another important check to make sure the method isn’t pushing us to overfit and find false positives
  - Statistical jack-knife/x-validation, fit on 90% of the data—what is the out of sample mean squared error? Do a stratification so we have data from each monitor and “era,” rural/suburban, high wind areas/not
- I downloaded hourly wind data from the AQS website to explore and get a sense of within-day variation
- While on the AQS website, I also downloaded a dataset on HAPS. The EPA has HAPS data going back to 1980, though there are fewer monitoring stations.
  - I visualized the HAPS monitoring stations in California. There are 39 HAPS stations, some of which are near new and active wells

### 10.18.2020 Su
- I incorporated the 2017 and 2019 upwind new wells datasets that Christina uploaded a few days ago into the analysis; the new data didn't change the overall impression of the results
- I revised Figure 3 to include the now-complete (i.e., all years 1999-2019) data on upwind new wells

### 10.17.2020 Sa
- Slack message to Marshall:
  - If we're confident with the upwind wells assessment + model specifications, then this (unsurprisingly) suggests that the count of days with upwind wells better captures exposure to these pollutants than integrating over a month without wind taken into account. So my proposed plan for the sibling study, based on this and our earlier conversations, is to move forward with the count of upwind well days per trimester within 0-1 / 1-3 / 3-10 km , with the caveat that this may not capture other aspects of oil/gas exposures like stress and water pollution. I already have the count of wells within annuli out to 10 km without wind for all the births, so we'll be able to compare
- Question: in areas with oil/gas wells, is well drilling (i.e., well spudding/completion) associated with oil/gas production? If so, could be hard to disentangle effect of preproduction vs production; if not, then the story (for the results for new wells so far) is more clear

### 10.15 2020 Th
- I finished the daily downwind exposure assessment! I bound all the rows of data together and exported the dataset as one RDS file for future analysis
-
- Meeting with Christina F
  - Updates:
    - We reviewed the draft Figure 3 (with results for upwind/downwind exposure to new wells)
  - Next steps:
    - Christina will finish the upwind exposure assessment over the next couple days and upload the data

### 10.13.2020 Tu
- I fit FE models for the upwind and downwind exposure data we have to date; a clear story is starting to emerge for PM2.5, less clear for other pollutants
- I made a draft of Figure 3 that combines upwind/downind point estimates + 95% CIs for NO2, O3, PM2.5, and SO2
- NAAQS standards, for reference to contextualize our findings  [link](https://www.epa.gov/criteria-air-pollutants/naaqs-table)
  - NO2
    - 1 hour (primary): 100 ppb
  - O3
    - 8 hour (primary): 0.070 ppm (or 70 ppb)
  - PM2.5
    - 1 year (primary): 12.0 μg/m^3
    - 24 hour (primary): 35 μg/m^3
  - SO2
    - 1 hour (primary): 75 ppb
    - 3 hour (secondary): 0.5 ppm or 500 ppb
- I added several new papers on oil/gas production and air quality to the project folder and started reading a few
  - We'll need to be careful in framing the study, particularly justifying the pollutants we focused on; refer to the critiques of the Hess et al. study

### 10.12.2020 M
- I sketched out drafts for figures 2 and 3 in my bullet journal
- I started the script for Figure 2, which will illustrate the exposure assessment methods
- As I was coding Figure 2, I ran into an issue with the upwind "wedge" that raised some concerns about whether or not we've done it accurately. I'll check the data to verify the accuracy. I should've done this earlier, before starting the long phase of running the analyses; a lesson for the future to be thorough with QA/QC before moving on to time-intensive analyses!
- I essentially already have drafts of Figure 3 in the results section for upwind/downwind exposure to new wells (currently in Rmd files)
- Christina F uploaded datasets for the daily annuli upwind new wells exposure assessment (she's continuing with the odd years); I copied them to my machine so I can include them in the preliminary analyses

### 10.10.2020 Sa
- I updated the tasks to reflect what I need to work on next; I'll make it a habit to do this regularly, at least weekly while I'm actively working on the project
- This project will now be labeled as ch. 2 of my dissertation (instead of ch. 3)

### 10.07.2020 W
- I'm continuing the annuli new wells downwind exp assessment on my machine; it should be done in the next week

### 10.06.2020 Tu
- The Tran et al. (where we got the PWT key) has a study period of 2006-2015; the data for this chapter come from 1999-2019
- Next: Join 2018/19 data using API number; explore the 1999-2017 (and 18/19) data with missing lat/long

### 10.05.2020 M
- For the past few days DG has been running the annuli exposure assessment for downwind new wells. CF has been finishing up the analysis for upwind new wells (she's doing odd-numbered years). Hopefully we'll be done with the upwind + downwind new wells exposure assessment by the end of the week.
- DG is working on tidying the CalGEM monthly well production data. The raw data we obtained from the CalGEM website don't include lat/long and use a PWT ID instead of the standard API number as the unique well identifier, which precludes us from joining the production data with other CalGEM and DrillingInfo datasets.
- DG used the PWT key that Kathy Tran shared (which includes lat/long). Using a subset of the data (1999-2002 data), I was able to join the lat/long from the PWT key with my own tidied CalGEM production data.
- Matching was successful for 50% of well-months. I was able to match lat/long for the majority well-months with oil/gas production. We have lat/long values for well-months accounting for 98.3% of oil production and 98.1% of gas production, 1999-2002. I'll verify whether this holds up for the full dataset.
- I used the same procedure as from the last point on the 1999-2017 CalGEM production data (the 2018-19 data include API number). Matching was successful for 70.6% of well-months. I was able to match lat/long for the majority well-months with oil/gas production. We have lat/long values for well-months accounting for 91.0% of oil production and 95.5% of gas production, 1999-2017. I'll verify whether this holds up for the full dataset.
- Next: Join 2018/19 data using API number; explore the 1999-2017 (and 18/19) data with missing lat/long

### 9.25.2020 F
- CF and DG met via Zoom to finish extracting the NARR temperature data for all the monitor-days
- We checked the correlation between modeled NARR temperature data and a subset of observed EPA temperature values; there was a strong correlation, with a r of ~0.91 and highly statistically significant result for a Pearson's correlation test (indicating a strong correlation)
- That, plus visual inspection, means that I think our NARR extraction method worked! We should be good to move on to re-assessing exposure using wind direction
- DG and CF will run the annuli exposure assessment for upwind wells over the weekend; CF will take odd years, DG even years

### 9.24.2020 Th
- DG and CF fixed a GIS issue we were having with EPA AQS monitoring sites not lining up correctly over NARR daily weather rasters; CF figured out a solution with a more efficient function and a method to match the projections (i.e., make both Lambert conformal conic)
- DG and CF extracted a subset of the NARR surface temperature data so we could compare modeled NARR temperature values against a subset of EPA observed temperature data at each station; we left off there

### 9.10.2020 Th
- DG revised and added to the methods in the Ch. 3 plan

### 8.27.2020 Th
- DG made another Rmd notebook, building off the one from yesterday, to generate preliminary results for the analysis using the monthly annuli exposure assessment for new wells
- I added figures to show the results for the models with all FEs
- SO2, NOx, and CO don't travel far in the atmosphere

### 8.26.2020 W
- I made a new Rmd notebook to generate preliminary results for the analysis using the monthly IDW exposure assessment for new wells

### 8.25.2020 Tu
- There seems to be an issue, in the data Christina and I generated most of the wind came from the northeast, but it should be coming from the northwest. Also, the NARR data didn’t seem to match the EPA data on wind direction. Maybe there was an issue extracting the data from the NARR rasters. I don’t think it was an issue with lining of the time (i.e., dates); when I made side-by-side wind roses comparing the subset of matched modeled NARR and observed EPA monitor-days, there was discordance even by season. Rather, there may have been an issue with the geographic alignment. I’ll check that tomorrow.
- This is time-sensitive, since I need to talk about this work in next week’s pre-recorded session for IAPHS.

### 8.19.2020 Th
- David G gave a presenatation at E-IPER lunch, which I'll adapt for my presentation at IAPHS next month

### 8.14.2020 F
- Christina F gave a great presentation at the SURGE symposium on the study design and preliminary results
- We spent the last two weeks working out the data tidying and exposure assessment code
- We were able to successfully assess exposure for upwind new wells

### 7.31.2020
- Today I worked on the tidy_narr_data.R script with the goal of writing a generalized function that can handle the different data types, efficiently process data from all years, and produce a tidy dataset.
- I started writing the tidyNARRData() function, which will import the given NARR data set by year, extract the raster of observations for each day in each year, store the rasters in a list, stacks them, intersect them with the AQS monitoring sites, converts the resulting dataset from wide to long format, changes the day of year to date, and returns a processed dataset with one observation for the given meteorological variable for each monitor-day, along with the monitor_id and date
- I figured out some of the technical details, i.e., how to unroll the list and handle different inputs
- Next I need to go through and convert what is now a one-time script to a repeatable function

### 7.29.2020
- Christina F submitted an abstract to AGU based on this project. I'm excited she'll get to share this work!

### 7.27.2020
- I copied over the assessExposureAnnuli() function from the Ch. 2 sibling study, which I just finished debugging. It should be straightforward to adapt this to the air quality study!

...

### 6.30.2020
- C.F. practiced pushing to the repository x2

### 6.29.2020
- DG revised the plan to reflect the current state of the project
- DG revised the readme document. The readme will be a static document; se the plan for updates.

### 6.22.2020
- SURGE started today! I'll be working with Christina Francis on this project now through August. After Christina gets up to speed on R and the study design, she and I will work together to write and edit code, assess exposure, and fit models fixed effects regression models.

...

### 5.26.2020
- I finished the code to generate the 'aqs_monitor_day' dataset and exported it as a .rds file in the data/interim/ subdirectory.
- I found that the raw temperature data included data from the entire U.S., so I added a line in tidyMeteorologicalData() to filter to California only
- A lesson in the efficiency differences between saveRDS() and write_csv(): saveRDS took approximately 45 seconds results in a 70.2 MB file; write_csv() took over 2 minutes, caused my MacBook Pro's fans to turn on, and produced a 1.2 GB file. Clearly, it makes sense to use .rds files for this project!
  - Note: This was *before* I found the extra rows coming from the temperature data, so the final .rds is smaller, but this is still illustrative!
- Units of observation:
  - CO - ppm
  - NO2 - ppb
  - O3 - ppm
  - PM2.5 - µg/m^3
  - PM10 - µg/m^3
  - SO2 - ppb
  - Barometric pressure -
  - Temperature - degrees Fahrenheit
  - Wind speed -
  - Wind direction -
- In the code to make the aqs_monitor_day dataset, there's an error in making the 'monitor_id' variable and its derivatives. There should be 9 digits for each 'monitor_id' but some have fewer.
  - I'll check each of the raw dataset inputs:
    - aqs_co_raw   - good (i.e., all monitors have 9 digits), 155 monitors
    - aqs_no2_raw  - good, 177 monitors
    - aqs_o3_raw   - good, 284 monitors
    - aqs_pm25_raw - good, 217 monitors
    - aqs_pm10_raw - good, 245 monitors
    - aqs_so2_raw  - good, 65 monitors
    - *Note:* This issue isn't coming from the air pollution observations
  - Next I'll check the raw meteorological data inputs. For these datasets, there is no `Site ID` variable as there is for the raw air pollution datasets. So for these datasets, I paste together the `State Code`, `County Code`, and `Site Num` variables to make the 'monitor_id' variable. I'll check to see if these vars are missing in the meteorological data:
    - aqs_press_raw - good
    - aqs_temp_raw  - I think I may have found the issue. Some of the `Site Num` observations seem to be missing leading zeroes (this should be a four-digit number). I'll add leading zeroes so that all observations of this variable have four digits. The `State Code` and `County Code` variables all look good to go.
    - aqs_wind_raw  - Same issue as above
- Tasks:
  - In tidyMeteorologicalData(), add leading zeroes when necessary to the `Site Num` variable before using it in the pipeline to generate the 'monitor_id' variable.
  - In making the aqs_monitor_month dataset, I need to figure out a way to deal with missing daily observations when I'm estimating monthly means.

### 5.23.2020
- I looked into gridded meteorological data that I can use in this and further analyses. I found a few potential sources.
- Regarding missingness in the US EPA AQS meteorology data, I remembered that I hadn't finished renaming the raw CSVs. I learned from *Efficient R Programming* that I should keep the raw data filenames intact to help with data provenance, so I'll do this for any new raw data adn leave the filenames I've already changed as-is
- Which meteorological data do I need? In their analysis, Deryugina et al. (2019) only used wind and temperature data.
- Relatedly, my takeaways from Buonocore et al. (2020) were:
  - SO2, NOx, and CO (and benzene, if I find data for it) have short atmospherric lifetimes, travel short distances; exposure should be assessed only at short distance
  - Incorporate upwind/downwind relationships between sources and monitors
  - Incorporate "fine-scale meteorological data, and ideally back-trajectory analysis"
  - Add'l metrics to consider: "cloud cover, wind speed, wind direction, and time of day"
  - Consider other sources of pollution: automobiles, other point sources
- For now I'll keep the wind, temperature, and air pressure data. I need to find precipitation data. I'll likely end up only keeping the wind, precip, and temperature data.
- In sum, I'll find sources for:
  - wind vectors - NARR daily reanalysis
  - temperature and precipitation - PRISM from U of Oregon (an alternative could be Daymet from Oak Ridge NL)
- Next: I'll verify that the 'aqs_monitor_day' dataset is good to go and export it as a .Rds, then mkke the 'aqs_monitor_month' dataset.

### 5.22.2020
- I revised the tidy_aqs_pollution_data.R script, with the aim of generating the 'aqs_monitor_day' dataset. I was able to successfully merge the data for the six air pollutants.
- There are many of missing observations in the meteorological data. I'll need to bring in different meteorological data, an also add precipitation data. I can look into what we have from the Burke Lab's COVID air quality datasets and see if I can find what I need there.
- Next: I'll finish adding the meteorological data to the 'aqs_monitor_day' dataset, then I'll use that dataset to generate the 'aqs_monitor_month' dataset, and then export both as .Rds files.
- I committed today's revisions to Github

### 5.19.2020
- Created a new GitHub repo for this project, since (a) I've rearranged it from Ch. 3 to Ch. 2, (b) I'm completely restructuring the codebase from scratch, and (c) I plan to share it publicly once it's finished.

### 5.18.2020
- I outlined the plan for this project by hand in my notebook, see photo

### 5.17.2020
- Over the past few days I've been reading [Efficient R Programming](https://csgillespie.github.io/efficientR/) by Gillespie and Lovelace. It's a practical and comprehensive text.
- I sketched out a plan for the Ch. 2 analysis by hand

...

### 5.4.2020
- I revised the 'plan-ch2.md' note, compiling some of the notes I've written for this project before (specifically, the background and rationale from a January Burke Lab session) and describing the revised approach to this study
- I'm trying a new naming convention for my R scripts: I added an additional prefix corresponding to the workflow stage (i.e., 0 for setup, 1 for import, 2 for tidying, etc). I did this because, when I have multiple scripts open in RStudio, I wasn't able to see where it is in the workflow; now I can see exactly where in the workflow each script is based on the prefix (e.g., 0.01-setup.R is the very first script).
- I need to update run_all.R to reflect this revision; I'll carry it over to Ch. 3, 4 if it still works for me
- I started a '6.01-make_figure1.R' script and wrote part of the code to make the map; I still need to add the monitoring sites to the map and decide on the buffer size for the wells (I think I may set the buffer size to whatever we find is relevant when we do the analysis)

### 5.1.2020
- I processed the daily wind data so that the raw CSVs now only include California data.
- I adapted the tidyAirQualityData() function to handle the meteorology data; we now have a tidyMeteorological() data function that produces datasets
- I think we can use wind as an exogenous source of variation for this and the births study, maybe; need to think about this more when I'm not tired
- I can also, hopefully, take advantage of daily variations in wind direction/speed to use the daily air quality observations.
- Next step is to tidy the other meteorological data, then link the meteorological data to the airnow_combined tibble, which should have everything. Once I have that, I'll explore the wind data and the airnow_combined data and look for match/missingness. Ideally we'll have few missing observations of wind; the other factors may not matter so much. I should also reach out to Lynne Hildemann to get her advice on this research Q, she may have thoughts! I also want to end up with two combined tibbles: observations of all pollutants, meteorology, and exposure (both IDW and annuli x both well count and production sum) for (1) each monitor-day and (2) each monitor-month. I can aim to get this done next week and fit some preliminary models (maybe the mothly data for now?) before my meeting with Marshall B on Wednesday! I also need to look into the right way to average wind speed and direction by month--is this approach advisable?

### 4.30.2020
- I searched through the US EPA AQS website to find daily meteorological data. I downloaded CSVs directly from [this site](https://aqs.epa.gov/aqsweb/airdata/download_files.html).
- This means I won't need to use the PWFSLSmoke package to download the data.
- I downloaded the daily data for: (1) relative humidity/dew point, (2) barometric pressure, (3) temperature, and (4) wind speed/direction
- I added code to the '01-import_raw_data.R' script to import the meteorological data
-

### 4.29.2020
- I downloaded hourly wind data from the EPA using PWFSLSmoke package. I tested the function and it seemed to work. However, I don't need hourly data; rather, I want daily data.
- How do we take daily/monthly average of wind direction & speed? Can I download daily data?

### 4.27.2020
- I began a new Rmd notebook to write a working example for wind direction, named '2020.04-we_wind_direction.Rmd'

### 4.23.2020
- Monthly production data from CalGEM
  - The identifying number in the pre-2018 data (PWT__ID in the raw data) is a 9-digit number and doesn't align with the 14-digit API number reported in the 2018-19 data (when the reporting format changed)
  - This [Wikipedia article](https://en.wikipedia.org/wiki/API_well_number#State_Code) breaks down what each of the digits in the API number refers to:

      An API well number can have up to 14 digits divided by dashes as follows:

      Example: 42-501-20130-03-00[4]

      The "42" means that this well is located in "State Code" 42 which is Texas. The "501" means that this well is located in "County Code" 501 which is Yoakum County. The "20130" is a "Unique Well Identifier" within the county. The "03" is the "Directional Sidetrack Code" for wells that have been sidetracked. The "00" is the "Event Sequence Code" to indicate how many operations have taken place.

      Most public databases that use API numbers are maintained by the individual oil and gas commissions, Therefore, they only require the "County Code" and "Unique Well Identifier." For an example, consult the Wyoming Oil and Gas Commission website
  - I downloaded a PDF document with a kewy for API state and county codes. They map to the 2018/19 API numbers as expected.
  - The PWT__ID numbers seems to be structured differently than the API numbers. All numbers start with a '100-' prefix, which doesn't correspond with the 3-digit California county codes (and obviously not all wells are located in the same county!). So I think I'm going to need some sort of key to match the PWT_ID and API numbers.
  - So now I'm hunting down what PWT means and whether there's a way to match the wells
  - This [CalGEM page](https://www.conservation.ca.gov/calgem/Pages/Well-Search.aspx) references PWT Status:
    - PWT Status: **Pool/well type** status relates to that particular pool and well type. It can be active, idle, cancelled, new, plugged, or buried-idle. Some wells do more than one thing, such as a cyclic steam well. For such wells, there will be a line for OG production, and a line for SC injection. So the PWT status on one line of a well can be different from the overall well status. EXAMPLE: A well that was converted from OG production to WF injection will have two lines, one for each segment. The well status will be active, the OG status will be plugged, and the WF status will be active
  - Some Google searching didn't come up with anything helpful, except for the note above.
  - I sent an email to Kathy Tran, the recent UCB PhD graduate from the Morello-Frosch lab group, to ask how she matched the PWT IDs and API numbers. I'll see if she has any leads, as I'm at a loss.
  - I made a new Rmd notebook to start exploring the monthly production data in aggregate. Since we're not able to link individual wells (pre-2018) using API numbers, I'm not able to look at geographic aspects of production, i.e., by county or field (the latter of which I suspect may be important). However, I can still look at trends within individual wells to get a sense of well-level variation.
- Email from Kathy Tran:
  "If my memory serves me well, I generated the PWT-API key from the MS Access databases that I downloaded from DOGGR back in 2015. I have the keys for 2000-2015. Let me know what years you're interested in. I've attached a key for 2015 but not sure this will match up with every well within the dataset you're going to use. Also fyi, PWT IDs are unique to each well but not API numbers - several PWTs can match up to the same API and I was informed that that likely means different wells are plugging into the same pool/source. I went thru a lot of pains to make sure I got this right so I can provide you with SAS code and/or the datasets I created if you're interested, but I will have to do a bit of digging because I generated them several years ago."

### 4.22.2020
- I'm back to working on this project after spending most of the last few weeks on revisions for the *Environmental Epidemiology* (Ch. 1) manuscript.
- I need to revise the prepProductionData to handle the pre-2018 data, which have slightly different formatting. Also, rather than an API number there's something called a 'PWT__ID' that appears to possibly be part of the API number, possibly missing leading/trailing zeroes. I'll look into it.

...

### 3.11.2020
- I emailed Joan Casey to ask her advice about working with wind data in California. She responded:
  "Here’s what my colleague Lucas Henneman said:
    Re: wind fields—lots of options. If annual or monthly datasets are okay, I have code written to go get files from a few different datasets (NARR is what I’ve been using for over the US—it’s resolution is ~32km). You can use the syntax from the first 30 lines of this script: https://github.com/lhenneman/HyADS_to_pm25/blob/master/RCode/hyads_to_pm25_month.R. Line 3 sources the functions in this file: https://github.com/lhenneman/HyADS_to_pm25/blob/master/RCode/hyads_to_pm25_functions.R"


### 3.6.2020
- I'm copying the draft abstract from below to continue iterating on it.
- Goals of the abstract: connect with theme, mention disparities (this is a focus of the conference), highlight interdisciplinarity of methods
- Outline of abstract (2,000 character limit, or ~350 words):
  - Background
    - An estimated 17.6 million U.S. residents live in within 1.6 km (1 mile) of active oil and gas wells, including 2.1 million Californians.
    - In California, residents belonging to racial/ethnic minority groups have disproportionately high exposure to well sites.
    - Recent studies have found associations between residential proximity to well sites and adverse reproductive, cardiovascular, and mental health outcomes.
    - These adverse health outcomes may be attributable to a range of exposures that may be associated with proximity to well sites, including community disruption, noise pollution, water pollution, and ambient air pollution.
    - However, the effect of oil and gas production activities on ambient air quality are not well characterized.
    - In this study, we leverage longitudinal observations throughout California to examine how activity at well sites affects the concentrations of ambient air pollutants.
  - Methods
    - We obtained data on oil and gas production activities, including the locations of well sites, from Enverus and the California Geologic Energy Management Division (CalGEM).
    - We also obtained data from the U.S. Environmental Protection Agency (EPA) Air Quality System at 284 stations throughout California, which included daily observations of carbon monoxide (CO), nitrogen dioxide (NO2), ozone (O3), sulfur dioxide (SO2), and particulate matter with a diameter of less than 10 µm (PM10) and of less than 2.5 µm (PM2.5).
    - We assessed exposure to wells sites for each air monitor and for each month during the study period (1999-2019), using an inverse distance-squared weighted (IDW) index for all well sites within 10 km of the monitor. We then classified each monitor-month as unexposed or exposed, dividing exposure into terciles based on the IDW index.
    - For each pollutant, we fit linear models with mean monthly concentration as the dependent variable and exposure tercile as the independent variable. - We also used an econometric approach, fitting a model with fixed effects for air basin-month and air basin-year. Air basins are defined by the California Air Resources Board (CARB) with boundaries determined based on similarity of geographic and meteorological features.
  - Results
    - In preliminary analyses, exposure to well sites was associated with higher concentrations of PM10 (p < 0.001) and PM2.5 (p < 0.001). These results were robust to the addition of fixed effects for air basin-month and air-basin year but were attenuated with an additional fixed effect for monitoring station.
  - Conclusion
    - We found evidence that exposure to oil and gas well sites is associated with higher concentrations of particulate matter, which may contribute to adverse health outcomes.
- Primary Submission Category: Environmental factors
- Secondary Submission Category: Place/communities
- Presentation Preference: I would like to be considered for both an oral or poster presentation


### 3.5.2020
- IAPHS abstract deadline is Monday (though the conference isn't until October...). I Slacked Marshall about submitting something based on this project and he agreed it's a good idea.
- Goals of the abstract: connect with theme, mention disparities (this is a focus of the conference), highlight interdisciplinarity of methods
- Outline of abstract (2,000 character limit, or ~350 words):
  - Background
    - An estimated __ million U.S. residents live within 1.6 km (1 mile) of active oil and gas wells sites, and recent studies have found...
    - Disparities in exposure to well sites; in California, Hispanic communities have disproportionately high exposure to well sites.
    - Proximity to well sites... community disruption, poor water quality, poor air quality
    - However, the effects of well sites on ambient air quality are not well understood...
    - In this study, we ...
  - Methods
    - We obtained data from the U.S. EPA Air Quality System for the concentrations of __ pollutants...
    - Data on oil and gas production [were obtained] from the California (CalGEM) and Enverus.
    - from mansucript: For this analysis, we obtained data from the U.S. Environmental Protection Agency (EPA) Air Quality System, which included daily observations of NO2, O3, PM10, and PM2.5 from 1998-2018 at 290 stations throughout California (eFigure 3). Using statewide data on oil and gas drilling activity, we assessed exposure to drilling sites for each air monitor and for each month from 1998-2018, using the same method as described above for maternal residences. For each pollutant, we fit linear models with mean monthly concentration as the dependent variable and exposure tercile as the independent variable. We also fit a model with fixed effects for air basin-month and air basin-year. Air basins are defined by the California Air Resources Board (CARB) with boundaries determined based on similarity of geographic and meteorological features.
  - Results
    - Monitors with higher exposure had higher concentrations of......
    - In a secondary analysis, exposure to drilling sites was associated with higher concentrations of PM10 and PM2.5 (eTable 12). These results were robust to the addition of fixed effects for air basin-month and air-basin year but were attenuated with an additional fixed effect for monitoring station.
  - Conclusion
    - We found evidence that exposure to oil and gas sites is associated with higher concentrations of ambient air pollutants.
- Primary Submission Category: Environmental factors
- Secondary Submission Category: Place/communities
- Presentation Preference: I would like to be considered for both an oral or poster presentation

### 2.28.2020
- I messaged Hemant to ask about his approach to using wind direction in his data. He said he used ArcMap to do that work (and scripted it in Python), and suggested a new R package that may be helpful: rWind. I installed the package and downloaded the vignette.
- Another resource to follow-up on: [California Environment Information Sources](http://libguides.humboldt.edu/c.php?g=303807&p=2029330) from Humboldt State University

### 2.25.2020
- I'm looking into wind direction/speed data data.
  - I found this note from the supplemental material for Casey et al. (2018), the California coal retirement paper. "Living downwind of coal and oil power plants may increase exposure to associated air pollution. Therefore, we calculated the number and proportion of days of pregnancy that mothers lived downwind. To do so, we purchased hourly wind data captured from weather stations located < 5km from the six power plants that retired between 2007- 2011 from Weather Source (https://weathersource.com/). Weather Source provided wind direction as a continuous variable in degrees ranging from 0 to 360, where 0 and 360 degrees indicate wind blowing from due north and wind speed as m/s. We estimated daily average wind direction from the closest weather station to each power plant. To determine the number of days during pregnancy that mothers lived downwind of power plants, we calculated the angle between each power plant and mothers’ residences at delivery and defined a downwind day as residence within 22.5o of the daily mean wind direction. We then divided mothers into three groups: those that never lived downwind during pregnancy (n = 10545 [18.5%]), those that lived downwind 1-90 days (n = 38,645, [67.8%]), and those that lived downwind ≥ 90 days during pregnancy (n = 7815, [13.7%])."
  - [WeatherSource](https://weathersource.com/) is a private dataset, need to pay for the data according to Casey et al. (2018)
- I Slacked Sam H-N to get his advice on wind data. His suggestions:
  -

### 2.24.2020
- Today, I'll start by answering the question: which oil fields do we have AQS monitors near?
  - Answer: 493 of the 516 fields in the dataset have a monitor nearby. However, only 25 monitors are within 10 km of one of the fields. Looking at the map in the data exploration for production data,
- On visual inspection, there appear to be areas of oil fields *without* O&G wells (at least those in preproduction or production in the study period, 1999-2019) as well as O&G wells *not* in fields. The latter was based on visual inspection of an O&G well buffer under the oil fields polygon shapefile, so I'll need to confirm that with at st_intersection operatio8n
- Also: which monitors are near oil fields? which monitors are near oil wells?
- Next, I'll start to answer the question: which ambient air pollutants are of concern, and how can I get data on them?
- Question: are all oil/gas wells located in CalGEM fields?
  - "Here is a link to some official CA weather stations that include wind data:
ftp://ftpcimis.water.ca.gov/pub2/. if you click on the readme.txt you can see the units that they have and then the individual files don’t have column headers These data are from CIMIS [California Irrigation Management Information System]"
  - "this groups has a bunch of pre-processed wind data available: https://globalwindatlas.info. I think they draw on, among other things, reanalysis data. and then for the raw gridded reanalysis data you should talk to Hemant. He knows those data much better than me"

### 2.22.2020
- I'm continuing to explore the CalGEM oil and gas production data. I added the data on oil fields and looked at production and count of wells by field.

### 2.21.2020
- From a message I Slacked to Marshall this morning:
  - I read papers on the effect of oil pricing on oil production. After reading a few of them, the upshot seems to be that:
    - The U.S., as a non-OPEC country, is a price-taker (though I wonder if this may have changed now that the U.S. is a leading oil producer?) (Ringlund et al. 2008); consequently, the causal arrow should point from price -> production, and not the reverse.
    - Maintaining production at developed fields/wells is relatively inexpensive and production typically unresponsive to oil price changes (Baumeister and Kilian 2016, Ringlund et al. 2008)
    - With oil price changes (sustained for at least ~6 months), investments in drilling new wells may be affected; therefore, the effect of price is likely to affect preproduction (Anderson et al. 2014, Baumeister and Kilian 2016). So, revising the above, my working hypothesis is that the causal arrow goes price -> preproduction (-> lagged production?).
    - I could look into the effect of price on drilling and production in the data  we have—do you think that's a good use of my time? This could help establish whether oil price is a good instrument for the preproduction bit, at least
  - After reviewing some literature, synthesizing my answers some questions that came up in conversation with Marshall B & Co.: Oil production seems unaffected by oil price fluctuations, but drilling and traffic are both likely to respond in ways that would reduce ambient air pollution, which would make the price of oil unhelpful in isolating the effect of drilling on air pollution, i.e., not a good instrument. Using shipping as an indication, other heavy industries dependent on fossil fuels are also likely to quickly respond to oil price fluctuations. (And I'm adding a note to my list of potential future research ideas to look into the effect of oil price on air pollution in the U.S.)

### 2.20.2020
- I read papers on the effect of oil pricing on oil production and took some notes

### 2.18.2020
- I continued with the data exploration for the production data.
- I added figure to visualize univariate distributions by county
- I worked on the '03-tidy_production_data.R' script, renaming variable names that are of interest to this analysis. In the future, I may need to add a script to tidy data before 2018.
- I added to the script to tidy the 2018/19 CalGEM production data, including renaming and selecting variables, and adding a column for date (i.e., month of reporting).
- I read up on oil and gas terms: condensation, water disposition, tubing, casing
- I continued to explore the CalGEM production data, including monthly production at example individual wells and all wells through time.
- I added to the .ppt for tomorrow

### 2.15.2020
- The annuli exposure assessment worked! I checked at ~8:20 am (when I woke up) and the assessment had finished. I exported the data and started to look at it, and it looks like it was successful.
- Note that this dataset only includes monitors within 15 km of at least one drilling site during the study period (1999-2019).
- To account for that^^, I added code in the import interim data script to import and join the exposure results to the full dataset.
- I finished the exposure assessment script and exported the final annuli dataset.
- I began a data exploration Rmd for the annuli exposure data, adapting the Rmd I'd already written for the IDW index.
- I fit some preliminary fixed effects models using the annuli, to get a sense of the results. They're confusingly inconsistent, I'm not sure what to make of it. I'll keep going with this analysis for now and bring it to Burke Lab on Wednesday for their thoughts.
- I made a Rmd notebook that makes a figure to visualize the distribution of well sites (in preproduction and production) around example monitors. See the '2020.02-monitor_exposure_examples.Rmd' notebook and the resulting '2020.02-monitor_exposure_examples.png' figure.
- Interpreting this figure: there is a wide range of what exposure looks like among different air quality monitors, from the Bakersfield monitor, surrounded by thousands of well sites to the northeast, to the Livermore site, which had three wells drilled to the east. This makes me think that it'll be important to account for: the density of well sites (maybe don't model linearly?), wind direction, topography, and meteorology. Also, roads and other pollution sources.
- I started next week's presentation for Burke Lab, where I'll explain the study and where I'm at right now.
- Next I'll explore the DOGGR production data, and prepare for the Burke Lab presentation. That should help me with determining whether to pursue this project further. After that, I'll transition back to working on the Ch. 2 analysis.

### 2.14.2020
- Note: I learned this week that the new name for DOGGR is the **California Geologic Energy Management Division (CalGEM)**
- I'm working on the '04-assess_expoosure_annuli.R' script
  - I added arguments for the assessExposureAnnuliGeneral() function: site_id, month_year, and site_id_month_year
  - I'm testing this function today to see if I can call it in a loop; the function should return a dataset with counts for wells in annuli bins (out to 10 km at this point, maybe out to 15 km later?) for the input month_year.
  - I need to add a way to account for the timing of the wells, i.e., restrict the well sites in preproduction and production to those with drilling/production intervals that intersect with the input month_year
  - Another note: I'm writing the function to accept point (coordinates) and
- I expanded the function to account for exposure out to 15 km from the site
- I tested inside the function on a sample point; it seems to work
- I tested a function call, feeding in one monitor-month at a time (along with all wells); it again seems to have worked, and quickly counted wells even for the most exposed monitor-month (as assessed using IDW)
- I wrote a script called '05-call_exposure_annuli.R' to loop through calling the exposure assessment. The script works, using a for loop to through each line.
- As it is now, the script is slow. Each iteration of the loop takes approximately 2.6 seconds. With 44,031 monitor-months to assess exposure for, this assessment would take over 31 hours to complete. To address this issue, I'll look into restricting the assessment to monitors within 15 km of well sites.
- Making this restriction, we have 17,845 monitor-months where the monitor was located within 15 km of at least one well site. Assuming 2.6 seconds per monitor-month, the assessment should take approximately 13 hours to complete. I'll run this overnight tonight.
- Note: I'll need to combine these exposure data with the rest of the data for monitors *not* within 15 km of a well site; I can do this step here later.
- I started running the function at approximately 6pm. I checked it at 10:15pm and it was on the 5,157th iteration of the loop.

### 2.13.2020
- Now that I've re-submitted the Ch. 1 manuscript, I can focus on this project.
- My goal is to present preliminary air pollution results at next Wednesday's Burke Lab meeting
- I worked on the '2.04-assess_exposure_annuli.R' script
  - I copied and pasted the function from the '2020.01-we_exposure_annuli.Rmd' notebook from Ch. 2
  - I need to generalize this function and call it in a loop (with point for the monitor and county wells)
  - Also, **need to append well_id and month_year columns to the output** (feed this in?)
- Should I add wells in post-production? Maybe in a future analysis?
- Also, consider making data exploration Rmd to visualize the exposure assessment; adapt from the '2020.01-we_exposure_annuli.Rmd' notebook, but use actual locations of monitors

### 2.5.2020
- I downloaded monthly oil and gas production data for 2019 from [this website](ftp://ftp.consrv.ca.gov/pub/oil/Online_Data/Production_Injection_Data/Pre-2018_Data_Format/) hosted by DOGGR. I already downloaded the 2018 data late last year.
- Pre-2018 monthly production data are available as Access databases, for 1977-2017. I'll look into those datasets later.
- My goal today is to explore the 2018 and 2019 monthly production data. I started a Rmd notebook in my Ch. 3 project folder for this purpose, it's called: '2020.02-doggr_production_data.Rmd'

### 1.28.2020
- The exposure assessment for wells in production stage I started last night didn't work, returned an error after monitor 57. I think this is because the machine went to sleep (despite my attempt to set it to stay awake!)
- Exposure assessment, IDW on wells in production stage
  - I re-started the exposure assessment at 7:15am
  - As of 3:10pm, the code was still running. Currently on monitor 77
  - Almost done at 5:23pm, at monitor 283
  - Done at 5:30pm, and the assessment seems to have been successful
- I exported the exposure assessment data as 'aqs_exposure_prod.csv'
- I updated the 'data_explo_exposure.Rmd' report to include the exposure data for wells in production stage
- Drafted first two paragraphs of potential future manuscript to present in Burke Lab tomorrow.

### 1.27.2020
- I finished downloading US EPA AQS data. We now have data from 1999-2019 for six pollutants: CO, NO2, O3, PM10, PM2.5, and SO2.
- Exposure assessment for sites in preproduction
  - Took several hours; kept computer running
  - Analysis was able to pick up after I had shut the computer
- Revised notebook for exposure to well sites in preprod
- Ran preliminary FE models; mixed but interesting results, showing evidence of elevated PM2.5 with higher exposure, even with station FE
- Edited IDW exposure assessment script to do assessment for wells in production stage and started running overnight

### 1.25.2020
- I copied code from the Ch. 1 Rmd notebook for the data exploration
- I downloaded data from US EPA AQS for NO2, O3, and PM2.5 up to 2019 for all monitors in California; this will allow me to fill out the study period
- For some reason I don't remember, I only have PM10 data from 1999 to 2003. I downloaded PM10 data up to 2019.
- I also started downloading carbon monoxide (CO) data, as I think this may be a pollutant of concern for oil and gas. I'll need to look into that more!
- Need to add SO2, too
- Started a literature review document

### 1.24.2020
- I organized the code and data, and worked on setting up the 'run_all.R' workflow.
- Note: The air quality data are from the US EPA Air Quality System (AQS) and were obtained from [here](https://www.epa.gov/outdoor-air-quality-data/download-daily-data).
- I restructured the workflow to tailor the old Ch. 2 code for the Ch. 3 analysis. This involved eliminating exposure assessment for the births data and restructuring the codebase to go through the inverse distance-weighted
- I started a Rmd notebook to do data exploration
- The study period for this chapter will be 1999 to 2019. I changed the dates in the prepDrillingData() function from 1997-2011 to 1999-2019, to reflect the range for which we have both air quality data and drilling data

### 1.22.2020
- I initiated a GitHub repo for this project and connected it to my machine.
- I set up a workspace in RStudio, copying the directory structure and some of the code from Ch. 2, for which I'm in full swing in the analysis.
